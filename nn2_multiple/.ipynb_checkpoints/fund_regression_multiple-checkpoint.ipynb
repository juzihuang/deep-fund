{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# 2 Layer Neural Network Regression\n",
    "\n",
    "In this project, 2 layer neural network is used for predicting funds index within a single csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Load and prepare the data\n",
    "\n",
    "A critical step in working with neural networks is preparing the data correctly. Variables on different scales make it difficult for the network to efficiently learn the correct weights. Below, we've written the code to load and prepare the data. You'll learn more about this soon!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here we start to load all the data as listed below:\n",
      "File 1: /Volumes/机器学习/发送文件/发送文件/1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 2: /Volumes/机器学习/发送文件/发送文件/2.csv\n",
      "File 3: /Volumes/机器学习/发送文件/发送文件/3.csv\n",
      "File 4: /Volumes/机器学习/发送文件/发送文件/4.csv\n",
      "File 5: /Volumes/机器学习/发送文件/发送文件/5.csv\n",
      "File 6: /Volumes/机器学习/发送文件/发送文件/6.csv\n",
      "File 7: /Volumes/机器学习/发送文件/发送文件/7.csv\n",
      "File 8: /Volumes/机器学习/发送文件/发送文件/8.csv\n",
      "File 9: /Volumes/机器学习/发送文件/发送文件/9.csv\n",
      "File 10: /Volumes/机器学习/发送文件/发送文件/10.csv\n",
      "File 11: /Volumes/机器学习/发送文件/发送文件/11.csv\n",
      "File 12: /Volumes/机器学习/发送文件/发送文件/12.csv\n",
      "File 13: /Volumes/机器学习/发送文件/发送文件/13.csv\n",
      "File 14: /Volumes/机器学习/发送文件/发送文件/14.csv\n",
      "File 15: /Volumes/机器学习/发送文件/发送文件/15.csv\n",
      "File 16: /Volumes/机器学习/发送文件/发送文件/16.csv\n",
      "File 17: /Volumes/机器学习/发送文件/发送文件/17.csv\n",
      "File 18: /Volumes/机器学习/发送文件/发送文件/18.csv\n",
      "File 19: /Volumes/机器学习/发送文件/发送文件/19.csv\n",
      "File 20: /Volumes/机器学习/发送文件/发送文件/20.csv\n",
      "File 21: /Volumes/机器学习/发送文件/发送文件/21.csv\n",
      "File 22: /Volumes/机器学习/发送文件/发送文件/22.csv\n",
      "File 23: /Volumes/机器学习/发送文件/发送文件/23.csv\n",
      "File 24: /Volumes/机器学习/发送文件/发送文件/24.csv\n",
      "File 25: /Volumes/机器学习/发送文件/发送文件/25.csv\n",
      "File 26: /Volumes/机器学习/发送文件/发送文件/26.csv\n",
      "File 27: /Volumes/机器学习/发送文件/发送文件/27.csv\n",
      "File 28: /Volumes/机器学习/发送文件/发送文件/28.csv\n",
      "File 29: /Volumes/机器学习/发送文件/发送文件/29.csv\n",
      "File 30: /Volumes/机器学习/发送文件/发送文件/30.csv\n",
      "File 31: /Volumes/机器学习/发送文件/发送文件/31.csv\n",
      "File 32: /Volumes/机器学习/发送文件/发送文件/32.csv\n",
      "File 33: /Volumes/机器学习/发送文件/发送文件/33.csv\n",
      "File 34: /Volumes/机器学习/发送文件/发送文件/34.csv\n",
      "File 35: /Volumes/机器学习/发送文件/发送文件/35.csv\n",
      "File 36: /Volumes/机器学习/发送文件/发送文件/36.csv\n",
      "File 37: /Volumes/机器学习/发送文件/发送文件/37.csv\n",
      "File 38: /Volumes/机器学习/发送文件/发送文件/38.csv\n",
      "File 39: /Volumes/机器学习/发送文件/发送文件/39.csv\n",
      "File 40: /Volumes/机器学习/发送文件/发送文件/40.csv\n",
      "File 41: /Volumes/机器学习/发送文件/发送文件/41.csv\n",
      "File 42: /Volumes/机器学习/发送文件/发送文件/42.csv\n",
      "File 43: /Volumes/机器学习/发送文件/发送文件/43.csv\n",
      "File 44: /Volumes/机器学习/发送文件/发送文件/44.csv\n",
      "File 45: /Volumes/机器学习/发送文件/发送文件/45.csv\n",
      "File 46: /Volumes/机器学习/发送文件/发送文件/46.csv\n",
      "File 47: /Volumes/机器学习/发送文件/发送文件/47.csv\n",
      "File 48: /Volumes/机器学习/发送文件/发送文件/48.csv\n",
      "File 49: /Volumes/机器学习/发送文件/发送文件/49.csv\n",
      "File 50: /Volumes/机器学习/发送文件/发送文件/50.csv\n",
      "File 51: /Volumes/机器学习/发送文件/发送文件/51.csv\n",
      "File 52: /Volumes/机器学习/发送文件/发送文件/52.csv\n",
      "File 53: /Volumes/机器学习/发送文件/发送文件/53.csv\n",
      "File 54: /Volumes/机器学习/发送文件/发送文件/54.csv\n",
      "File 55: /Volumes/机器学习/发送文件/发送文件/55.csv\n",
      "File 56: /Volumes/机器学习/发送文件/发送文件/56.csv\n",
      "File 57: /Volumes/机器学习/发送文件/发送文件/57.csv\n",
      "File 58: /Volumes/机器学习/发送文件/发送文件/58.csv\n",
      "File 59: /Volumes/机器学习/发送文件/发送文件/59.csv\n",
      "File 60: /Volumes/机器学习/发送文件/发送文件/60.csv\n",
      "File 61: /Volumes/机器学习/发送文件/发送文件/61.csv\n",
      "File 62: /Volumes/机器学习/发送文件/发送文件/62.csv\n",
      "File 63: /Volumes/机器学习/发送文件/发送文件/63.csv\n",
      "File 64: /Volumes/机器学习/发送文件/发送文件/64.csv\n",
      "File 65: /Volumes/机器学习/发送文件/发送文件/65.csv\n",
      "File 66: /Volumes/机器学习/发送文件/发送文件/66.csv\n",
      "File 67: /Volumes/机器学习/发送文件/发送文件/67.csv\n",
      "File 68: /Volumes/机器学习/发送文件/发送文件/68.csv\n",
      "File 69: /Volumes/机器学习/发送文件/发送文件/69.csv\n",
      "File 70: /Volumes/机器学习/发送文件/发送文件/70.csv\n",
      "File 71: /Volumes/机器学习/发送文件/发送文件/71.csv\n",
      "File 72: /Volumes/机器学习/发送文件/发送文件/72.csv\n",
      "File 73: /Volumes/机器学习/发送文件/发送文件/73.csv\n",
      "File 74: /Volumes/机器学习/发送文件/发送文件/74.csv\n",
      "File 75: /Volumes/机器学习/发送文件/发送文件/75.csv\n",
      "File 76: /Volumes/机器学习/发送文件/发送文件/76.csv\n",
      "File 77: /Volumes/机器学习/发送文件/发送文件/77.csv\n",
      "File 78: /Volumes/机器学习/发送文件/发送文件/78.csv\n",
      "File 79: /Volumes/机器学习/发送文件/发送文件/79.csv\n",
      "File 80: /Volumes/机器学习/发送文件/发送文件/80.csv\n",
      "File 81: /Volumes/机器学习/发送文件/发送文件/81.csv\n",
      "File 82: /Volumes/机器学习/发送文件/发送文件/82.csv\n",
      "File 83: /Volumes/机器学习/发送文件/发送文件/83.csv\n",
      "File 84: /Volumes/机器学习/发送文件/发送文件/84.csv\n",
      "File 85: /Volumes/机器学习/发送文件/发送文件/85.csv\n",
      "File 86: /Volumes/机器学习/发送文件/发送文件/86.csv\n",
      "File 87: /Volumes/机器学习/发送文件/发送文件/87.csv\n",
      "File 88: /Volumes/机器学习/发送文件/发送文件/88.csv\n",
      "File 89: /Volumes/机器学习/发送文件/发送文件/89.csv\n",
      "File 90: /Volumes/机器学习/发送文件/发送文件/90.csv\n",
      "File 91: /Volumes/机器学习/发送文件/发送文件/91.csv\n",
      "File 92: /Volumes/机器学习/发送文件/发送文件/92.csv\n",
      "File 93: /Volumes/机器学习/发送文件/发送文件/93.csv\n",
      "File 94: /Volumes/机器学习/发送文件/发送文件/94.csv\n",
      "File 95: /Volumes/机器学习/发送文件/发送文件/95.csv\n",
      "File 96: /Volumes/机器学习/发送文件/发送文件/96.csv\n",
      "File 97: /Volumes/机器学习/发送文件/发送文件/97.csv\n",
      "File 98: /Volumes/机器学习/发送文件/发送文件/98.csv\n",
      "File 99: /Volumes/机器学习/发送文件/发送文件/99.csv\n",
      "File 100: /Volumes/机器学习/发送文件/发送文件/100.csv\n"
     ]
    }
   ],
   "source": [
    "# Here is where we get the raw data\n",
    "\n",
    "data_list = ['/Volumes/机器学习/发送文件/发送文件/1.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/2.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/3.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/4.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/5.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/6.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/7.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/8.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/9.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/10.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/11.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/12.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/13.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/14.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/15.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/16.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/17.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/18.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/19.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/20.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/21.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/22.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/23.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/24.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/25.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/26.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/27.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/28.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/29.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/30.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/31.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/32.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/33.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/34.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/35.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/36.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/37.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/38.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/39.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/40.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/41.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/42.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/43.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/44.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/45.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/46.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/47.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/48.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/49.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/50.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/51.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/52.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/53.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/54.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/55.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/56.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/57.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/58.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/59.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/60.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/61.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/62.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/63.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/64.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/65.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/66.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/67.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/68.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/69.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/70.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/71.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/72.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/73.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/74.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/75.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/76.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/77.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/78.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/79.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/80.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/81.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/82.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/83.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/84.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/85.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/86.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/87.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/88.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/89.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/90.csv',\n",
    "             '/Volumes/机器学习/发送文件/发送文件/91.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/92.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/93.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/94.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/95.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/96.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/97.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/98.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/99.csv', \n",
    "             '/Volumes/机器学习/发送文件/发送文件/100.csv']\n",
    "\n",
    "# Here we set 'header' equals to None to indicate that there are no headers in the csv\n",
    "# file, Here the index is int64 rather than string.\n",
    "for idx, data_path in enumerate(data_list):\n",
    "    if idx == 0:\n",
    "        raw_data = pd.read_csv(data_path, delimiter=',', header=None)\n",
    "        print('Here we start to load all the data as listed below:')\n",
    "        print('File %d:' %(idx+1), data_path)\n",
    "    else:\n",
    "        raw_data_temp = pd.read_csv(data_path, delimiter=',', header=None)\n",
    "        raw_data = raw_data.append(raw_data_temp)\n",
    "        print('File %d:' %(idx+1), data_path)\n",
    "\n",
    "# Get the target labels in the second column and use remaining columns as feature\n",
    "targets = raw_data[2]\n",
    "\n",
    "# the first column is really large which doesn't mean anything and the first second\n",
    "# column is all the same which makes it impossible to get scaled\n",
    "features = raw_data.drop([0, 1, 2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>756</th>\n",
       "      <th>757</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.633065</td>\n",
       "      <td>-0.008128</td>\n",
       "      <td>0.045430</td>\n",
       "      <td>-0.002063</td>\n",
       "      <td>-0.013119</td>\n",
       "      <td>-0.007422</td>\n",
       "      <td>-0.006651</td>\n",
       "      <td>-0.007802</td>\n",
       "      <td>-0.006543</td>\n",
       "      <td>-0.000501</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.465103</td>\n",
       "      <td>-0.011930</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>-0.023502</td>\n",
       "      <td>-0.027506</td>\n",
       "      <td>-0.015769</td>\n",
       "      <td>-0.018849</td>\n",
       "      <td>-0.015969</td>\n",
       "      <td>-0.018974</td>\n",
       "      <td>-0.014387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.466022</td>\n",
       "      <td>-0.012439</td>\n",
       "      <td>-0.023620</td>\n",
       "      <td>-0.027816</td>\n",
       "      <td>-0.031575</td>\n",
       "      <td>-0.024687</td>\n",
       "      <td>-0.015381</td>\n",
       "      <td>-0.019730</td>\n",
       "      <td>-0.018320</td>\n",
       "      <td>-0.017956</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.288603</td>\n",
       "      <td>-0.015906</td>\n",
       "      <td>-0.042954</td>\n",
       "      <td>-0.014294</td>\n",
       "      <td>-0.008752</td>\n",
       "      <td>-0.012817</td>\n",
       "      <td>-0.008098</td>\n",
       "      <td>-0.008985</td>\n",
       "      <td>-0.006139</td>\n",
       "      <td>-0.006387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.517867</td>\n",
       "      <td>-0.007269</td>\n",
       "      <td>-0.014323</td>\n",
       "      <td>-0.038031</td>\n",
       "      <td>-0.026898</td>\n",
       "      <td>-0.025223</td>\n",
       "      <td>-0.024893</td>\n",
       "      <td>-0.015078</td>\n",
       "      <td>-0.011522</td>\n",
       "      <td>-0.011530</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        3         4         5         6         7         8         9    \\\n",
       "0  0.633065 -0.008128  0.045430 -0.002063 -0.013119 -0.007422 -0.006651   \n",
       "1  0.465103 -0.011930  0.018900 -0.023502 -0.027506 -0.015769 -0.018849   \n",
       "2  0.466022 -0.012439 -0.023620 -0.027816 -0.031575 -0.024687 -0.015381   \n",
       "3  0.288603 -0.015906 -0.042954 -0.014294 -0.008752 -0.012817 -0.008098   \n",
       "4  0.517867 -0.007269 -0.014323 -0.038031 -0.026898 -0.025223 -0.024893   \n",
       "\n",
       "        10        11        12  ...   756  757  758  759  760  761  762  763  \\\n",
       "0 -0.007802 -0.006543 -0.000501 ...   0.0  0.0  0.0  0.0  1.0  1.0  1.0  1.0   \n",
       "1 -0.015969 -0.018974 -0.014387 ...   0.0  0.0  0.0  0.0  0.0  1.0  1.0  0.0   \n",
       "2 -0.019730 -0.018320 -0.017956 ...   0.0  0.0  0.0  0.0  1.0  1.0  0.0  1.0   \n",
       "3 -0.008985 -0.006139 -0.006387 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4 -0.015078 -0.011522 -0.011530 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   764  765  \n",
       "0  0.0  0.0  \n",
       "1  0.0  0.0  \n",
       "2  0.0  0.0  \n",
       "3  0.0  0.0  \n",
       "4  0.0  0.0  \n",
       "\n",
       "[5 rows x 763 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of the features\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Scaling target variables (optional)\n",
    "To make training the network easier, we'll standardize each of the continuous variables. That is, we'll shift and scale the variables such that they have zero mean and a standard deviation of 1.\n",
    "\n",
    "The scaling factors are saved so we can go backwards when we use the network for predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "quant_features = features.T.index.tolist()\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "mean, std = targets.mean(), targets.std()\n",
    "scales_target = [mean, std]\n",
    "targets = (targets - mean)/std\n",
    "\n",
    "scales_feature = {}\n",
    "for each in quant_features:\n",
    "    mean, std = features[each].mean(), features[each].std()\n",
    "    scales_feature[each] = [mean, std]\n",
    "    features.loc[:, each] = (features[each] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Splitting the data into training, testing, and validation sets\n",
    "\n",
    "We'll split the data into two sets, one for training and one for validating as the network is being trained. Since this is time series data, we'll train on historical data, then try to predict on future data (the validation set). We'll save the last 400 samples of the data to use as a test set after we've trained the network. We'll use this set to make predictions and compare them with the actual number of riders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Save the last 400 as test data\n",
    "test_features, test_targets = features[-400:], targets[-400:]\n",
    "data_features, data_targets = features[:-400], targets[:-400]\n",
    "\n",
    "# Hold out the last 400 of the remaining data as a validation set\n",
    "val_features, val_targets = data_features[-400:], data_targets[-400:]\n",
    "train_features, train_targets = data_features[:-400], data_targets[:-400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>756</th>\n",
       "      <th>757</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.946550</td>\n",
       "      <td>-0.107417</td>\n",
       "      <td>1.298845</td>\n",
       "      <td>0.035518</td>\n",
       "      <td>-0.352499</td>\n",
       "      <td>-0.164777</td>\n",
       "      <td>-0.145028</td>\n",
       "      <td>-0.215010</td>\n",
       "      <td>-0.159201</td>\n",
       "      <td>0.185914</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014104</td>\n",
       "      <td>-0.043175</td>\n",
       "      <td>-0.123476</td>\n",
       "      <td>-0.340207</td>\n",
       "      <td>2.129158</td>\n",
       "      <td>1.647201</td>\n",
       "      <td>1.360469</td>\n",
       "      <td>2.027669</td>\n",
       "      <td>-0.297166</td>\n",
       "      <td>-0.462037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010033</td>\n",
       "      <td>-0.189502</td>\n",
       "      <td>0.693011</td>\n",
       "      <td>-0.604178</td>\n",
       "      <td>-0.874227</td>\n",
       "      <td>-0.514388</td>\n",
       "      <td>-0.714762</td>\n",
       "      <td>-0.632199</td>\n",
       "      <td>-0.842635</td>\n",
       "      <td>-0.629167</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014104</td>\n",
       "      <td>-0.043175</td>\n",
       "      <td>-0.123476</td>\n",
       "      <td>-0.340207</td>\n",
       "      <td>-0.469667</td>\n",
       "      <td>1.647201</td>\n",
       "      <td>1.360469</td>\n",
       "      <td>-0.493175</td>\n",
       "      <td>-0.297166</td>\n",
       "      <td>-0.462037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.015156</td>\n",
       "      <td>-0.200508</td>\n",
       "      <td>-0.277938</td>\n",
       "      <td>-0.732928</td>\n",
       "      <td>-1.021761</td>\n",
       "      <td>-0.887919</td>\n",
       "      <td>-0.552784</td>\n",
       "      <td>-0.824287</td>\n",
       "      <td>-0.806685</td>\n",
       "      <td>-0.838674</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014104</td>\n",
       "      <td>-0.043175</td>\n",
       "      <td>-0.123476</td>\n",
       "      <td>-0.340207</td>\n",
       "      <td>2.129158</td>\n",
       "      <td>1.647201</td>\n",
       "      <td>-0.735037</td>\n",
       "      <td>2.027669</td>\n",
       "      <td>-0.297166</td>\n",
       "      <td>-0.462037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.974092</td>\n",
       "      <td>-0.275360</td>\n",
       "      <td>-0.719447</td>\n",
       "      <td>-0.329447</td>\n",
       "      <td>-0.194137</td>\n",
       "      <td>-0.390774</td>\n",
       "      <td>-0.212614</td>\n",
       "      <td>-0.275416</td>\n",
       "      <td>-0.136948</td>\n",
       "      <td>-0.159588</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014104</td>\n",
       "      <td>-0.043175</td>\n",
       "      <td>-0.123476</td>\n",
       "      <td>-0.340207</td>\n",
       "      <td>-0.469667</td>\n",
       "      <td>-0.607088</td>\n",
       "      <td>-0.735037</td>\n",
       "      <td>-0.493175</td>\n",
       "      <td>-0.297166</td>\n",
       "      <td>-0.462037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.304233</td>\n",
       "      <td>-0.088884</td>\n",
       "      <td>-0.065639</td>\n",
       "      <td>-1.037733</td>\n",
       "      <td>-0.852171</td>\n",
       "      <td>-0.910362</td>\n",
       "      <td>-0.997055</td>\n",
       "      <td>-0.586655</td>\n",
       "      <td>-0.432929</td>\n",
       "      <td>-0.461492</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014104</td>\n",
       "      <td>-0.043175</td>\n",
       "      <td>-0.123476</td>\n",
       "      <td>-0.340207</td>\n",
       "      <td>-0.469667</td>\n",
       "      <td>-0.607088</td>\n",
       "      <td>-0.735037</td>\n",
       "      <td>-0.493175</td>\n",
       "      <td>-0.297166</td>\n",
       "      <td>-0.462037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 763 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        3         4         5         6         7         8         9    \\\n",
       "0  0.946550 -0.107417  1.298845  0.035518 -0.352499 -0.164777 -0.145028   \n",
       "1  0.010033 -0.189502  0.693011 -0.604178 -0.874227 -0.514388 -0.714762   \n",
       "2  0.015156 -0.200508 -0.277938 -0.732928 -1.021761 -0.887919 -0.552784   \n",
       "3 -0.974092 -0.275360 -0.719447 -0.329447 -0.194137 -0.390774 -0.212614   \n",
       "4  0.304233 -0.088884 -0.065639 -1.037733 -0.852171 -0.910362 -0.997055   \n",
       "\n",
       "        10        11        12     ...          756       757       758  \\\n",
       "0 -0.215010 -0.159201  0.185914    ...    -0.014104 -0.043175 -0.123476   \n",
       "1 -0.632199 -0.842635 -0.629167    ...    -0.014104 -0.043175 -0.123476   \n",
       "2 -0.824287 -0.806685 -0.838674    ...    -0.014104 -0.043175 -0.123476   \n",
       "3 -0.275416 -0.136948 -0.159588    ...    -0.014104 -0.043175 -0.123476   \n",
       "4 -0.586655 -0.432929 -0.461492    ...    -0.014104 -0.043175 -0.123476   \n",
       "\n",
       "        759       760       761       762       763       764       765  \n",
       "0 -0.340207  2.129158  1.647201  1.360469  2.027669 -0.297166 -0.462037  \n",
       "1 -0.340207 -0.469667  1.647201  1.360469 -0.493175 -0.297166 -0.462037  \n",
       "2 -0.340207  2.129158  1.647201 -0.735037  2.027669 -0.297166 -0.462037  \n",
       "3 -0.340207 -0.469667 -0.607088 -0.735037 -0.493175 -0.297166 -0.462037  \n",
       "4 -0.340207 -0.469667 -0.607088 -0.735037 -0.493175 -0.297166 -0.462037  \n",
       "\n",
       "[5 rows x 763 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Head of the scaled features\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Build the network\n",
    "\n",
    "The network has two layers, a hidden layer and an output layer. The hidden layer will use the sigmoid function for activations. The output layer has only one node and is used for the regression, the output of the node is the same as the input of the node. That is, the activation function is $f(x)=x$. A function that takes the input signal and generates an output signal, but takes into account the threshold, is called an activation function. We work through each layer of our network calculating the outputs for each neuron. All of the outputs from one layer become inputs to the neurons on the next layer. This process is called *forward propagation*.\n",
    "\n",
    "We use the weights to propagate signals forward from the input to the output layers in a neural network. We use the weights to also propagate error backwards from the output back into the network to update our weights. This is called *backpropagation*.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights_input_to_hidden = np.random.normal(0.0, self.hidden_nodes**-0.5, \n",
    "                                       (self.hidden_nodes, self.input_nodes))\n",
    "\n",
    "        self.weights_hidden_to_output = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                       (self.output_nodes, self.hidden_nodes))\n",
    "        self.lr = learning_rate\n",
    "        \n",
    "        #### Set this to your implemented sigmoid function ####\n",
    "        # Activation function is the sigmoid function\n",
    "        self.sigmoid = lambda x: 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def train(self, inputs_list, targets_list):\n",
    "        # Convert inputs list to 2d array\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        targets = np.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        #### Implement the forward pass here ####\n",
    "        ### Forward pass ###\n",
    "        # TODO: Hidden layer\n",
    "        hidden_inputs = np.dot(self.weights_input_to_hidden, inputs)# signals into hidden layer\n",
    "        hidden_outputs = self.sigmoid(hidden_inputs)# signals from hidden layer\n",
    "        \n",
    "        # TODO: Output layer\n",
    "        final_inputs = np.dot(self.weights_hidden_to_output, hidden_outputs)# signals into final output layer\n",
    "        final_outputs = final_inputs# signals from final output layer\n",
    "        \n",
    "        #### Implement the backward pass here ####\n",
    "        ### Backward pass ###\n",
    "        \n",
    "        # TODO: Output error\n",
    "        output_errors = targets - final_outputs # Output layer error is the difference between desired target and actual output.\n",
    "        output_grad = output_errors\n",
    "        \n",
    "        # TODO: Backpropagated error\n",
    "        hidden_errors = np.dot(self.weights_hidden_to_output.T, output_grad)# errors propagated to the hidden layer\n",
    "        hidden_grad = hidden_outputs * (1 - hidden_outputs)# hidden layer gradients\n",
    "        \n",
    "        # TODO: Update the weights\n",
    "        # import pdb; pdb.set_trace()\n",
    "        self.weights_hidden_to_output += np.dot(output_grad, hidden_outputs.T) * self.lr# update hidden-to-output weights with gradient descent step\n",
    "        self.weights_input_to_hidden += np.dot(hidden_errors * hidden_grad, inputs.T) * self.lr# update input-to-hidden weights with gradient descent step\n",
    "         \n",
    "        \n",
    "    def run(self, inputs_list):\n",
    "        # Run a forward pass through the network\n",
    "        inputs = np.array(inputs_list, ndmin=2).T\n",
    "        \n",
    "        #### Implement the forward pass here ####\n",
    "        # TODO: Hidden layer\n",
    "        hidden_inputs = inputs# signals into hidden layer\n",
    "        hidden_outputs = self.sigmoid(np.dot(self.weights_input_to_hidden, hidden_inputs))# signals from hidden layer\n",
    "        \n",
    "        # TODO: Output layer\n",
    "        final_inputs = hidden_outputs# signals into final output layer\n",
    "        final_outputs = np.dot(self.weights_hidden_to_output, final_inputs)# signals from final output layer \n",
    "        \n",
    "        return final_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def MSE(y, Y):\n",
    "    return np.mean((y-Y)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Training the network\n",
    "\n",
    "Set the hyperparameters for the network. The strategy here is to find hyperparameters such that the error on the training set is low, but you're not overfitting to the data. If you train the network too long or have too many hidden nodes, it can become overly specific to the training set and will fail to generalize to the validation set. That is, the loss on the validation set will start increasing as the training set loss drops.\n",
    "\n",
    "We use a method know as Stochastic Gradient Descent (SGD) to train the network. The idea is that for each training pass, you grab a random sample of the data instead of using the whole data set. More training passes could also be used than with normal gradient descent, but each pass is much faster. This ends up training the network more efficiently. You'll learn more about SGD later.\n",
    "\n",
    "### Choose the number of epochs\n",
    "This is the number of times the dataset will pass through the network, each time updating the weights. As the number of epochs increases, the network becomes better and better at predicting the targets in the training set. You'll need to choose enough epochs to train the network well but not too many or you'll be overfitting.\n",
    "\n",
    "### Choose the learning rate\n",
    "This scales the size of weight updates. If this is too big, the weights tend to explode and the network fails to fit the data. A good choice to start at is 0.1. If the network has problems fitting the data, try reducing the learning rate. Note that the lower the learning rate, the smaller the steps are in the weight updates and the longer it takes for the neural network to converge.\n",
    "\n",
    "### Choose the number of hidden nodes\n",
    "The more hidden nodes you have, the more accurate predictions the model will make. Try a few different numbers and see how it affects the performance. You can look at the losses dictionary for a metric of the network performance. If the number of hidden units is too low, then the model won't have enough space to learn and if it is too high there are too many options for the direction that the learning can take. The trick here is to find the right balance in number of hidden units you choose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 73.3% ... Training loss: 0.863 ... Validation loss: 1.025"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "### Set the hyperparameters here ###\n",
    "epochs = 600\n",
    "\n",
    "### It's better got set no larger than 0.01 if the features are scaled\n",
    "learning_rate = 0.0001\n",
    "hidden_nodes = 300\n",
    "output_nodes = 1\n",
    "\n",
    "N_i = train_features.shape[1]\n",
    "network = NeuralNetwork(N_i, hidden_nodes, output_nodes, learning_rate)\n",
    "\n",
    "losses = {'train':[], 'validation':[]}\n",
    "for e in range(epochs):\n",
    "    # Go through a random batch of 128 records from the training data set\n",
    "    batch = np.random.choice(train_features.index, size=128)\n",
    "    for record, target in zip(train_features.ix[batch].values, \n",
    "                              train_targets.ix[batch]):\n",
    "        network.train(record, target)\n",
    "    \n",
    "    # Printing out the training progress\n",
    "    train_loss = MSE(network.run(train_features), train_targets.values)\n",
    "    val_loss = MSE(network.run(val_features), val_targets.values)\n",
    "    sys.stdout.write(\"\\rProgress: \" + str(100 * e/float(epochs))[:4] \\\n",
    "                     + \"% ... Training loss: \" + str(train_loss)[:5] \\\n",
    "                     + \" ... Validation loss: \" + str(val_loss)[:5])\n",
    "    \n",
    "    losses['train'].append(train_loss)\n",
    "    losses['validation'].append(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses['train'], label='Training loss')\n",
    "plt.plot(losses['validation'], label='Validation loss')\n",
    "plt.legend()\n",
    "plt.ylim(ymax=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "\n",
    "# mean, std = scales_target\n",
    "# predictions = network.run(train_features[0:2000])*std + mean\n",
    "predictions = network.run(train_features[0:400]).T\n",
    "ax.plot(predictions[:,0], label='Prediction')\n",
    "\n",
    "# ax.plot((train_targets[0:2000]*std + mean).values, label='Data')\n",
    "ax.plot(train_targets[0:400].values, label='Ground Truth')\n",
    "ax.set_xlim(right=len(predictions))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "\n",
    "# mean, std = scales_target\n",
    "# predictions = network.run(val_features)*std + mean\n",
    "predictions = network.run(val_features).T\n",
    "ax.plot(predictions[:,0], label='Prediction')\n",
    "# ax.plot((val_targets*std + mean).values, label='Data')\n",
    "\n",
    "ax.plot(val_targets.values, label='Ground Truth')\n",
    "ax.set_xlim(right=len(predictions))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Predictions on Testing data\n",
    "\n",
    "Here, use the test data to view how well the network is modeling the data. If something is completely wrong here, make sure each step in your network is implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,4))\n",
    "\n",
    "# mean, std = scales_target\n",
    "# predictions = network.run(test_features)*std + mean\n",
    "predictions = network.run(test_features).T\n",
    "ax.plot(predictions[:,0], label='Prediction')\n",
    "# ax.plot((test_targets*std + mean).values, label='Data')\n",
    "\n",
    "ax.plot(test_targets.values, label='Ground Truth')\n",
    "ax.set_xlim(right=len(predictions))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions[:,0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Unit tests\n",
    "\n",
    "Run these unit tests to check the correctness of the network implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".EF..\n",
      "======================================================================\n",
      "ERROR: test_data_loaded (__main__.TestMethods)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-1b584817c956>\", line 21, in test_data_loaded\n",
      "    self.assertTrue(isinstance(rides, pd.DataFrame))\n",
      "NameError: name 'rides' is not defined\n",
      "\n",
      "======================================================================\n",
      "FAIL: test_data_path (__main__.TestMethods)\n",
      "----------------------------------------------------------------------\n",
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-26-1b584817c956>\", line 17, in test_data_path\n",
      "    self.assertTrue(data_path.lower() == 'bike-sharing-dataset/hour.csv')\n",
      "AssertionError: False is not true\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 5 tests in 0.020s\n",
      "\n",
      "FAILED (failures=1, errors=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=5 errors=1 failures=1>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "inputs = [0.5, -0.2, 0.1]\n",
    "targets = [0.4]\n",
    "test_w_i_h = np.array([[0.1, 0.4, -0.3], \n",
    "                       [-0.2, 0.5, 0.2]])\n",
    "test_w_h_o = np.array([[0.3, -0.1]])\n",
    "\n",
    "class TestMethods(unittest.TestCase):\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for data loading\n",
    "    ##########\n",
    "    \n",
    "    def test_data_path(self):\n",
    "        # Test that file path to dataset has been unaltered\n",
    "        self.assertTrue(data_path.lower() == 'bike-sharing-dataset/hour.csv')\n",
    "        \n",
    "    def test_data_loaded(self):\n",
    "        # Test that data frame loaded\n",
    "        self.assertTrue(isinstance(rides, pd.DataFrame))\n",
    "    \n",
    "    ##########\n",
    "    # Unit tests for network functionality\n",
    "    ##########\n",
    "\n",
    "    def test_activation(self):\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        # Test that the activation function is a sigmoid\n",
    "        self.assertTrue(np.all(network.sigmoid(0.5) == 1/(1+np.exp(-0.5))))\n",
    "\n",
    "    def test_train(self):\n",
    "        # Test that weights are updated correctly on training\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "        \n",
    "        network.train(inputs, targets)\n",
    "        self.assertTrue(np.allclose(network.weights_hidden_to_output, \n",
    "                                    np.array([[ 0.37275328, -0.03172939]])))\n",
    "        self.assertTrue(np.allclose(network.weights_input_to_hidden,\n",
    "                                    np.array([[ 0.10562014,  0.39775194, -0.29887597],\n",
    "                                              [-0.20185996,  0.50074398,  0.19962801]])))\n",
    "\n",
    "    def test_run(self):\n",
    "        # Test correctness of run method\n",
    "        network = NeuralNetwork(3, 2, 1, 0.5)\n",
    "        network.weights_input_to_hidden = test_w_i_h.copy()\n",
    "        network.weights_hidden_to_output = test_w_h_o.copy()\n",
    "\n",
    "        self.assertTrue(np.allclose(network.run(inputs), 0.09998924))\n",
    "\n",
    "suite = unittest.TestLoader().loadTestsFromModule(TestMethods())\n",
    "unittest.TextTestRunner().run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
